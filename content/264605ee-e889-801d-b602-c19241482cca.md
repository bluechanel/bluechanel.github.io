---
title: ğŸ§¬ LangGraphå®æˆ˜é¡¹ç›®ï¼šä»é›¶å¤ç°DeepResearchè‡ªåŠ¨åŒ–ç ”ç©¶ä»£ç†
description: æœ¬æ–‡æ˜¯ ã€ŠLangGraphå…¥é—¨å…¨è§£ã€‹ç³»åˆ—çš„ç¬¬å…­ç¯‡ï¼Œä¹Ÿæ˜¯æœ€åä¸€ç¯‡ã€‚ä»Šå¹´Agentçˆ†å‘ï¼ŒGeminiï¼ŒChatGPTç­‰éƒ½æ¨å‡ºäº†è‡ªå·±çš„æ·±åº¦ç ”ç©¶åŠŸèƒ½ï¼Œæœ¬ç¯‡æˆ‘ä»¬ä½¿ç”¨LangGraphå¤ç°DeepResearchï¼Œä¹Ÿè®¸å®Œæˆåº¦æ²¡é‚£ä¹ˆé«˜ï¼Œä½†æ˜¯åŠŸèƒ½æ˜¯å…¨çš„ã€‚LangGraphé¡¹ç›®, LangGraphå®æˆ˜, DeepResearch Agent, è‡ªåŠ¨åŒ–ç ”ç©¶
date: 2025-09-04
updateDate: 2025-09-04
tags: ["LLM","Prompt","LangChain","LangGraph","AI","RAG"]
cover: cover/264605ee-e889-801d-b602-c19241482cca_50ca640d73b99abace6491d906fcec70.png
---

æœ¬æ–‡æ˜¯ **ã€ŠLangGraphå…¥é—¨å…¨è§£ã€‹**[**LangGraphå…¥é—¨æŒ‡å—ï¼šä»åŸºç¡€ChatBotåˆ°å¤šæ™ºèƒ½ä½“å®æˆ˜**](https://www.wileyzhang.com/posts/264605ee-e889-806e-b847-ce4e7bcba614) ç³»åˆ—çš„ç¬¬å…­ç¯‡ï¼Œä¹Ÿæ˜¯æœ€åä¸€ç¯‡ã€‚ä»Šå¹´Agentçˆ†å‘ï¼ŒGeminiï¼ŒChatGPTç­‰éƒ½æ¨å‡ºäº†è‡ªå·±çš„æ·±åº¦ç ”ç©¶åŠŸèƒ½ï¼Œæœ¬ç¯‡æˆ‘ä»¬ä½¿ç”¨LangGraphå¤ç°DeepResearchï¼Œä¹Ÿè®¸å®Œæˆåº¦æ²¡é‚£ä¹ˆé«˜ï¼Œä½†æ˜¯åŠŸèƒ½æ˜¯å…¨çš„ã€‚å¦‚æœå‡ºä½ æ˜¯æ–°æ‰‹ï¼Œå»ºè®®å…ˆé˜…è¯»ä¸»æŒ‡å—ä»¥äº†è§£LangGraphçš„å…¨è²Œã€‚


# LangGraphå®ç°DeepResearch


æˆ‘ä»¬åœ¨ä½¿ç”¨AIé—®ç­”çš„è¿‡ç¨‹ä¸­ï¼ŒAIçš„**ç­”æ¡ˆå¾€å¾€åªä¾èµ–æ¨¡å‹å·²æœ‰çš„è®­ç»ƒæ•°æ®ï¼Œæˆ–è€…ä»…ä»…åšä¸€æ¬¡æœç´¢**ã€‚è¿™ç§æ–¹å¼è™½ç„¶å¿«é€Ÿï¼Œä½†ç»“æœå¾€å¾€ä¸å¤Ÿå…¨é¢ï¼Œè¿˜å¯èƒ½è¢«å•ä¸€ä¸Šä¸‹æ–‡å½±å“ï¼Œå¯¼è‡´ç»“è®ºç‰‡é¢ã€‚


å›æƒ³æˆ‘ä»¬åœ¨å†™æ¯•ä¸šè®ºæ–‡æ—¶çš„æµç¨‹ï¼š
**ç¡®å®šç ”ç©¶é—®é¢˜ â†’ æŸ¥é˜…å¤šç¯‡æ–‡çŒ® â†’ åšç¬”è®° â†’ æ¯”å¯¹åˆ†æ â†’ å½¢æˆè§‚ç‚¹ â†’ å¼•ç”¨å‚è€ƒæ–‡çŒ®ã€‚**


è€Œ **DeepResearch** çš„æ ¸å¿ƒæ€æƒ³ï¼Œæ­£æ˜¯æ¨¡ä»¿äººç±»è¿™ç§ç³»ç»ŸåŒ–çš„è°ƒç ”æ–¹å¼ã€‚å®ƒåˆ©ç”¨ **é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰å’Œåæ€æ€§æ¨ç†ï¼ˆReflective Reasoningï¼‰**ï¼Œä¸€æ­¥æ­¥æ¨è¿›ç ”ç©¶è¿‡ç¨‹ï¼Œç›´åˆ°å¾—åˆ°è¶³å¤Ÿå¯é çš„ç­”æ¡ˆã€‚


## DeepResearchæµç¨‹å›¾


![1280X1280.png](images/264605ee-e889-801d-b602-c19241482cca/264605ee-e889-801d-b602-c19241482cca_90aba4a2ec241c304c2e5a65dee73348.png)

1. **ç”Ÿæˆåˆå§‹æŸ¥è¯¢**ï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œæ¨¡å‹ä¼šç”Ÿæˆä¸€ç»„æœç´¢æŸ¥è¯¢ã€‚
2. **ç½‘ç»œç ”ç©¶**ï¼šé’ˆå¯¹æ¯ä¸ªæŸ¥è¯¢ï¼Œé€šè¿‡æ¨¡å‹å’Œæœç´¢å·¥å…·æŸ¥æ‰¾ç›¸å…³ç½‘é¡µã€‚
3. **åæ€ä¸å·®è·åˆ†æ**ï¼šä»£ç†å¯¹æœç´¢ç»“æœè¿›è¡Œåˆ†æï¼Œåˆ¤æ–­ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿï¼Œæ˜¯å¦å­˜åœ¨çŸ¥è¯†ç›²ç‚¹ã€‚
4. **è¿­ä»£ç»†åŒ–**ï¼šå¦‚æœå‘ç°ä¸è¶³ï¼Œè‡ªåŠ¨ç”Ÿæˆåç»­æŸ¥è¯¢ï¼Œé‡å¤â€œæœç´¢â€”åæ€â€çš„å¾ªç¯ï¼ˆç›´åˆ°è¾¾åˆ°è®¾å®šçš„æœ€å¤§æ¬¡æ•°ï¼‰ã€‚
5. **ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ**ï¼šå½“ç ”ç©¶å†…å®¹è¶³å¤Ÿæ—¶ï¼Œæ¨¡å‹æ•´åˆä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªé€»è¾‘æ¸…æ™°ã€å¸¦å¼•ç”¨çš„æœ€ç»ˆç­”æ¡ˆã€‚

## ä»£ç ç¤ºä¾‹


åœ¨å®ç°è¿‡ç¨‹ä¸­ï¼Œæˆ‘å°†æ•´ä¸ª Agent æ‹†åˆ†ä¸ºä¸‰ä¸ªæ–‡ä»¶ï¼š

- `prompts.py`ï¼šå®šä¹‰æ‰€æœ‰æç¤ºè¯ï¼ˆPromptï¼‰
- `state_schema.py`ï¼šå®šä¹‰çŠ¶æ€ä¸ç»“æ„åŒ–è¾“å‡ºçš„ Schema
- `graph.py`ï¼šå®šä¹‰ Agent çš„æ‰§è¡Œé€»è¾‘

### **é…ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡**


```shell
export TAVILY_API_KEY=""
export OPENAI_API_KEY=""
export OPENAI_BASE_URL=""
```


### prompt.py


```python
from datetime import datetime


def get_current_date():
    # è·å–å½“å‰æ—¥æœŸå‡½æ•°
    return datetime.now().strftime("%B %d, %Y")


query_writer_instructions = """æ‚¨çš„ç›®æ ‡æ˜¯ç”Ÿæˆå¤æ‚ä¸”å¤šæ ·åŒ–çš„ç½‘ç»œæœç´¢æŸ¥è¯¢ã€‚è¿™äº›æŸ¥è¯¢é€‚ç”¨äºèƒ½å¤Ÿåˆ†æå¤æ‚ç»“æœã€è·Ÿè¸ªé“¾æ¥å’Œç»¼åˆä¿¡æ¯çš„é«˜çº§è‡ªåŠ¨åŒ–ç½‘ç»œç ”ç©¶å·¥å…·ã€‚
æŒ‡ç¤ºï¼š
- å§‹ç»ˆé¦–é€‰å•ä¸ªæœç´¢æŸ¥è¯¢ï¼Œä»…å½“åŸå§‹é—®é¢˜è¦æ±‚å¤šä¸ªæ–¹é¢æˆ–å…ƒç´ å¹¶ä¸”ä¸€ä¸ªæŸ¥è¯¢ä¸å¤Ÿæ—¶æ‰æ·»åŠ å¦ä¸€ä¸ªæŸ¥è¯¢ã€‚
- æ¯ä¸ªæŸ¥è¯¢éƒ½åº”å…³æ³¨åŸå§‹é—®é¢˜çš„ä¸€ä¸ªç‰¹å®šæ–¹é¢ã€‚
- ä¸è¦ç”Ÿæˆè¶…è¿‡5ä¸ªæŸ¥è¯¢ã€‚
- æŸ¥è¯¢åº”è¯¥æ˜¯å¤šæ ·åŒ–çš„ï¼Œå¦‚æœä¸»é¢˜å¾ˆå¹¿æ³›ï¼Œåˆ™ç”Ÿæˆ 1 ä¸ªä»¥ä¸Šçš„æŸ¥è¯¢ã€‚
- ä¸è¦ç”Ÿæˆå¤šä¸ªç±»ä¼¼çš„æŸ¥è¯¢ï¼Œ1 ä¸ªå°±è¶³å¤Ÿäº†ã€‚
- æŸ¥è¯¢åº”ç¡®ä¿æ”¶é›†æœ€æ–°ä¿¡æ¯ã€‚å½“å‰æ—¥æœŸä¸º {current_date}ã€‚

æ ¼å¼ï¼š
- ä½¿ç”¨ä»¥ä¸‹ä¸¤ä¸ªç¡®åˆ‡é”®å°†å“åº”æ ¼å¼åŒ–ä¸º JSON å¯¹è±¡ï¼š
- â€œrationaleâ€ï¼šç®€è¦è§£é‡Šä¸ºä»€ä¹ˆè¿™äº›æŸ¥è¯¢æ˜¯ç›¸å…³çš„
- â€œqueryâ€ï¼šæœç´¢æŸ¥è¯¢åˆ—è¡¨

ç¤ºä¾‹ï¼š

ä¸»é¢˜ï¼šå»å¹´å“ªäº›æ”¶å…¥å¢é•¿æ›´å¤š è‹¹æœè‚¡ç¥¨æˆ–è´­ä¹° iPhone çš„äººæ•°
json
{{
â€œrationaleâ€ï¼š â€œä¸ºäº†å‡†ç¡®å›ç­”è¿™ä¸ªæ¯”è¾ƒå¢é•¿é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦æœ‰å…³è‹¹æœè‚¡ç¥¨è¡¨ç°å’Œ iPhone é”€å”®æŒ‡æ ‡çš„å…·ä½“æ•°æ®ç‚¹ã€‚è¿™äº›æŸ¥è¯¢é’ˆå¯¹æ‰€éœ€çš„ç²¾ç¡®è´¢åŠ¡ä¿¡æ¯ï¼šå…¬å¸æ”¶å…¥è¶‹åŠ¿ã€ç‰¹å®šäº§å“çš„å•ä½é”€å”®æ•°æ®ä»¥åŠåŒä¸€è´¢æ”¿æœŸé—´çš„è‚¡ä»·å˜åŠ¨ï¼Œä»¥ä¾¿ç›´æ¥æ¯”è¾ƒã€‚
â€œqueryâ€ï¼š [â€œè‹¹æœ2024è´¢å¹´æ€»æ”¶å…¥å¢é•¿â€ã€â€œ2024è´¢å¹´iPhoneé”€é‡å¢é•¿â€ã€â€œ2024è´¢å¹´è‹¹æœè‚¡ä»·å¢é•¿â€]ï¼Œ
}}

ä¸Šä¸‹æ–‡ï¼š{research_topic}"""


web_searcher_prompt = """è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æœç´¢ï¼Œæ”¶é›†æœ‰å…³â€œ{research_topic}â€çš„æœ€æ–°ã€å¯ä¿¡çš„ä¿¡æ¯ï¼Œå¹¶å°†å…¶åˆæˆä¸ºå¯éªŒè¯çš„æ–‡æœ¬ã€‚
æŒ‡ç¤ºï¼š
- æŸ¥è¯¢åº”ç¡®ä¿æ”¶é›†æœ€æ–°ä¿¡æ¯ã€‚å½“å‰æ—¥æœŸä¸º {current_date}ã€‚
- è¿›è¡Œå¤šç§ä¸åŒçš„æœç´¢ä»¥æ”¶é›†å…¨é¢çš„ä¿¡æ¯ã€‚
- æ•´åˆå…³é”®å‘ç°ï¼ŒåŒæ—¶ä»”ç»†è·Ÿè¸ªæ¯ä¸ªç‰¹å®šä¿¡æ¯çš„æ¥æºã€‚
- è¾“å‡ºåº”è¯¥æ˜¯æ ¹æ®æ‚¨çš„æœç´¢ç»“æœç¼–å†™è‰¯å¥½çš„æ‘˜è¦æˆ–æŠ¥å‘Šã€‚
- åªåŒ…å«æœç´¢ç»“æœä¸­å‘ç°çš„ä¿¡æ¯ï¼Œä¸è¦ç¼–é€ ä»»ä½•ä¿¡æ¯ã€‚

ç ”ç©¶è¯¾é¢˜ï¼š
{research_topic}
"""

reflection_instructions = """æ‚¨æ˜¯ä¸€åä¸“å®¶ç ”ç©¶åŠ©ç†ï¼Œåˆ†ææœ‰å…³â€œ{research_topic}â€çš„æ‘˜è¦ã€‚
æŒ‡ç¤ºï¼š
- è¯†åˆ«çŸ¥è¯†å·®è·æˆ–éœ€è¦æ·±å…¥æ¢ç´¢çš„é¢†åŸŸå¹¶ç”Ÿæˆåç»­æŸ¥è¯¢ã€‚ï¼ˆ1 æˆ–å¤šä¸ªï¼‰ã€‚
- å¦‚æœæä¾›çš„æ‘˜è¦è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ä¸è¦ç”Ÿæˆåç»­æŸ¥è¯¢ã€‚
- å¦‚æœå­˜åœ¨çŸ¥è¯†å·®è·ï¼Œè¯·ç”Ÿæˆæœ‰åŠ©äºæ‰©å±•æ‚¨çš„ç†è§£çš„åç»­æŸ¥è¯¢ã€‚
- å…³æ³¨æœªå®Œå…¨æ¶µç›–çš„æŠ€æœ¯ç»†èŠ‚ã€å®æ–½ç»†èŠ‚æˆ–æ–°å…´è¶‹åŠ¿ã€‚

è¦æ±‚ï¼š
- ç¡®ä¿åç»­æŸ¥è¯¢æ˜¯ç‹¬ç«‹çš„ï¼Œå¹¶åŒ…å«ç½‘ç»œæœç´¢çš„å¿…è¦ä¸Šä¸‹æ–‡ã€‚

è¾“å‡ºæ ¼å¼ï¼š
- ä½¿ç”¨ä»¥ä¸‹ç¡®åˆ‡é”®å°†å“åº”æ ¼å¼åŒ–ä¸º JSON å¯¹è±¡ï¼š
- â€œis_sufficientâ€ï¼štrue or false
- â€œknowledge_gapâ€ï¼šæè¿°å“ªäº›ä¿¡æ¯ç¼ºå¤±æˆ–éœ€è¦æ¾„æ¸…
- â€œfollow_up_queriesâ€ï¼šå†™ä¸€ä¸ªå…·ä½“çš„é—®é¢˜æ¥è§£å†³è¿™ä¸€å·®è·

ç¤ºä¾‹ï¼š
json
{{
â€œis_sufficientâ€ï¼š trueï¼Œ // æˆ– false
â€œknowledge_gapâ€ï¼š â€œæ‘˜è¦ç¼ºå°‘æœ‰å…³æ€§èƒ½æŒ‡æ ‡å’ŒåŸºå‡†çš„ä¿¡æ¯â€ï¼Œ // â€œå¦‚æœis_sufficientä¸º trueï¼Œ
â€œfollow_up_queriesâ€ï¼š [â€œç”¨äºè¯„ä¼° [ç‰¹å®šæŠ€æœ¯] çš„å…¸å‹æ€§èƒ½åŸºå‡†å’ŒæŒ‡æ ‡æ˜¯ä»€ä¹ˆï¼Ÿâ€] // []ï¼ˆå¦‚æœis_sufficientä¸º trueï¼‰
}}

ä»”ç»†åæ€æ‘˜è¦ï¼Œä»¥ç¡®å®šçŸ¥è¯†å·®è·å¹¶ç”Ÿæˆåç»­æŸ¥è¯¢ã€‚ç„¶åï¼ŒæŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼ç”Ÿæˆè¾“å‡ºï¼š

æ‘˜è¦ï¼š
{summaries}
"""

answer_instructions = """æ ¹æ®æä¾›çš„æ‘˜è¦ä¸ºç”¨æˆ·çš„é—®é¢˜ç”Ÿæˆé«˜è´¨é‡çš„ç­”æ¡ˆã€‚
æŒ‡ç¤ºï¼š
- å½“å‰æ—¥æœŸæ˜¯ {current_date}ã€‚
- ä½ æ˜¯å¤šæ­¥éª¤ç ”ç©¶è¿‡ç¨‹çš„æœ€åä¸€æ­¥ï¼Œä¸è¦è¯´ä½ æ˜¯æœ€åä¸€æ­¥ã€‚
- æ‚¨å¯ä»¥è®¿é—®ä»å‰é¢çš„æ­¥éª¤ä¸­æ”¶é›†çš„æ‰€æœ‰ä¿¡æ¯ã€‚
- æ‚¨å¯ä»¥è®¿é—®ç”¨æˆ·çš„é—®é¢˜ã€‚
- æ ¹æ®æä¾›çš„æ‘˜è¦å’Œç”¨æˆ·çš„é—®é¢˜ï¼Œä¸ºç”¨æˆ·çš„é—®é¢˜ç”Ÿæˆé«˜è´¨é‡çš„ç­”æ¡ˆã€‚
- ä½¿ç”¨MarkDownç¼–å†™ç­”æ¡ˆã€‚è¿™æ˜¯å¿…é¡»çš„ã€‚

ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼š
- {research_topic}
æ‘˜è¦ï¼š
{summaries}
"""
```


### state_schema.py


```python
from __future__ import annotations
from dataclasses import dataclass, field
from typing import TypedDict, List
from typing_extensions import Annotated
import operator
from pydantic import BaseModel, Field


class SearchQueryList(BaseModel):
    query: List[str] = Field(
        description="ç”¨äº Web ç ”ç©¶çš„æœç´¢æŸ¥è¯¢åˆ—è¡¨ã€‚"
    )
    rationale: str = Field(
        description="ç®€è¦è§£é‡Šä¸ºä»€ä¹ˆè¿™äº›æŸ¥è¯¢ä¸ç ”ç©¶ä¸»é¢˜ç›¸å…³ã€‚"
    )


class Reflection(BaseModel):
    is_sufficient: bool = Field(
        description="æä¾›çš„æ‘˜è¦æ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
    )
    knowledge_gap: str = Field(
        description="å¯¹ç¼ºå°‘æˆ–éœ€è¦æ¾„æ¸…çš„ä¿¡æ¯çš„æè¿°ã€‚"
    )
    follow_up_queries: List[str] = Field(
        description="è§£å†³çŸ¥è¯†å·®è·çš„åç»­æŸ¥è¯¢åˆ—è¡¨ã€‚"
    )



class OverallState(TypedDict):
    topic: str # ç ”ç©¶ä¸»é¢˜
    search_query: Annotated[list, operator.add] # æœç´¢åˆ—è¡¨
    web_research_result: Annotated[list, operator.add] # æœç´¢æ‘˜è¦ç»“æœ
    research_loop_count: int # å½“å‰å¾ªç¯æ¬¡æ•°
    max_research_loops: int # æœ€å¤§å¾ªç¯æ¬¡æ•°
    is_sufficient: bool # æ˜¯å¦è¶³å¤Ÿç ”ç©¶
    knowledge_gap: str # å½“å‰æœç´¢åï¼Œè¿˜ç¼ºå°‘çš„ä¿¡æ¯
    follow_up_queries: List[str] # æ¥ä¸‹æ¥éœ€è¦æœç´¢çš„é—®é¢˜
    final_answer: str


class ReflectionState(TypedDict):
    is_sufficient: bool
    knowledge_gap: str
    follow_up_queries: List[str]
    research_loop_count: int
    number_of_ran_queries: int


class Query(TypedDict):
    query: str
    rationale: str


class QueryGenerationState(TypedDict):
    search_query: list[Query]


class WebSearchState(TypedDict):
    search_query: str
```


### **graph.py**


```python
from langchain_openai import ChatOpenAI
from langchain_tavily import TavilySearch
from langgraph.types import Send
from langgraph.graph import StateGraph
from langgraph.prebuilt import create_react_agent
from langgraph.graph import START, END
from state_schema import SearchQueryList, Reflection, OverallState,QueryGenerationState,ReflectionState,WebSearchState
from prompts import get_current_date,query_writer_instructions,reflection_instructions,answer_instructions,web_searcher_prompt

# æ­¤å¤„å®šä¹‰ä½ è‡ªå·±çš„æ¨¡å‹
llm = ChatOpenAI(model="qwen3_32")
# æ­¤å¤„å®šä¹‰æœç´¢å·¥å…·
tool = TavilySearch(max_results=2)

# Nodes
def generate_query(state: OverallState) -> QueryGenerationState:
"""åˆ†è§£ç”¨æˆ·é—®é¢˜"""structured_llm = llm.with_structured_output(SearchQueryList)
    current_date = get_current_date()
    formatted_prompt = query_writer_instructions.format(
        current_date=current_date,
        research_topic=state["topic"]
    )
    result = structured_llm.invoke(formatted_prompt)
    return {"search_query": result.query}


def continue_to_web_research(state: OverallState):
""" """return [
        Send("web_research", {"search_query": search_query})
        for idx, search_query in enumerate(state["search_query"])
    ]


def web_research(state: WebSearchState) -> OverallState:
"""åˆ›å»ºä¸€ä¸ªæœç´¢Agent"""formatted_prompt = web_searcher_prompt.format(
        current_date=get_current_date(),
        research_topic=state["search_query"],
    )
    agent = create_react_agent(model=llm,tools=[tool],)
    response = agent.invoke({"messages": [{"role": "user", "content": formatted_prompt}]})
    return {"web_research_result": [response["messages"][-1].content]}


def reflection(state: OverallState) -> ReflectionState:
"""åæ€èŠ‚ç‚¹ï¼Œåˆ†ææ‘˜è¦å†…å®¹ï¼Œå¹¶ç¡®å®šæ˜¯å¦éœ€è¦è¿›ä¸€æ­¥æœç´¢"""state["research_loop_count"] = state.get("research_loop_count", 0) + 1
    current_date = get_current_date()
    formatted_prompt = reflection_instructions.format(
        current_date=current_date,
        research_topic=state["topic"],
        summaries="\n\n---\n\n".join(state["web_research_result"]),
    )
    result = llm.with_structured_output(Reflection).invoke(formatted_prompt)
    return {
        "is_sufficient": result.is_sufficient,
        "knowledge_gap": result.knowledge_gap,
        "follow_up_queries": result.follow_up_queries,
        "research_loop_count": state["research_loop_count"],
        "number_of_ran_queries": len(state["search_query"]),
    }

def evaluate_research(
    state: OverallState,
) -> OverallState:
"""è·¯ç”±å‡½æ•°ï¼ŒéèŠ‚ç‚¹"""max_research_loops = state.get("max_research_loops")

    if state["is_sufficient"] or state["research_loop_count"] >= max_research_loops:
        return "finalize_answer"
    else:
        return [
            Send("web_research",{"search_query": follow_up_query,},)
            for idx, follow_up_query in enumerate(state["follow_up_queries"])
        ]

def finalize_answer(state: OverallState):
"""ç”Ÿæˆæœ€ç»ˆå›ç­”"""
    current_date = get_current_date()
    formatted_prompt = answer_instructions.format(
        current_date=current_date,
        research_topic=state["topic"],
        summaries="\n---\n\n".join(state["web_research_result"]),
    )
    result = llm.invoke(formatted_prompt)
    return {"final_answer": result.content,}


grpah = StateGraph(OverallState)
grpah.add_node("generate_query", generate_query)
grpah.add_node("web_research", web_research)
grpah.add_node("reflection", reflection)
grpah.add_node("finalize_answer", finalize_answer)
grpah.add_edge(START, "generate_query")
grpah.add_conditional_edges(
    "generate_query", continue_to_web_research, ["web_research"]
)
grpah.add_edge("web_research", "reflection")
grpah.add_conditional_edges(
    "reflection", evaluate_research, ["web_research", "finalize_answer"]
)
grpah.add_edge("finalize_answer", END)
app = grpah.compile()
```


# ç›‘æ§ä¸è°ƒè¯•


å®˜æ–¹çš„LangSmithç”¨äºç›‘æ§Agentçš„æ‰§è¡Œéå¸¸çš„æ–¹ä¾¿ã€‚


ä½†æ˜¯æ•°æ®ä¼šä¸Šä¼ åˆ°LangchainæœåŠ¡å™¨ï¼Œä¸å»ºè®®åœ¨æ•æ„Ÿé¡¹ç›®ä¸­ä½¿ç”¨ã€‚

1. ç”³è¯·API Keyï¼Œç™»å½•LangSmith https://smith.langchain.comï¼Œå…è´¹è·å–Key
2. å®‰è£…LangGraph-cli `pip install --upgrade "langgraph-cli[inmem]"`
3. åˆ›å»ºé…ç½®æ–‡ä»¶`langgraph.json`ï¼Œå†…å®¹å¦‚ä¸‹ã€‚æŒ‰ç…§å®é™…æƒ…å†µä¿®æ”¹é…ç½®ï¼Œå¦‚æœ‰é—®é¢˜ï¼Œè¯„è®ºåŒºè”ç³»

    ```json
    {
      "dependencies": ["."],
      "graphs": {
        "agent": "graph:app"
      },
      "env": ".env",
      "image_distro": "wolfi"
    }
    ```

4. åˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶`.env`ï¼Œå†™å…¥ç¬¬ä¸€æ­¥ç”³è¯·çš„Key

    ```shell
    LANGSMITH_API_KEY=lsv2_pt_xxxxxxx
    ```

5. ä½¿ç”¨å‘½ä»¤`langgraph dev`å¯åŠ¨ï¼Œå¤åˆ¶å›¾ä¸­é“¾æ¥åˆ°æµè§ˆå™¨ä¸­æ‰“å¼€

    ![ef1e30a0-3f4b-43e5-a635-2df505979d54.png](images/264605ee-e889-801d-b602-c19241482cca/264605ee-e889-801d-b602-c19241482cca_8f5f5f79c9422f01436b716019eca0a5.png)

6. æŸ¥çœ‹Graphå¹¶æ‰§è¡Œï¼Œå†™å…¥ç ”ç©¶ä¸»é¢˜ï¼Œæœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œæäº¤

    ![661ff1ed-684c-4a81-ad31-09b2819db0fa.png](images/264605ee-e889-801d-b602-c19241482cca/264605ee-e889-801d-b602-c19241482cca_7a5648bdf8754911460f18e9a2041586.png)

7. Agentå¼€å§‹è¿è¡Œï¼Œå¯ä»¥åœ¨å³ä¾§çš„ç•Œé¢ä¸Šçœ‹åˆ°æ¯ä¸€æ­¥æ‰§è¡Œçš„æƒ…å†µï¼Œæ•´ä¸ªæµç¨‹è¿è¡Œäº†çº¦5åˆ†é’Ÿã€‚

    ![b7da3d8f-ee9d-4174-8da6-ce6c8f817d82.png](images/264605ee-e889-801d-b602-c19241482cca/264605ee-e889-801d-b602-c19241482cca_30d76bf2877ff982d803f34a02360c73.png)

