---
title: ğŸ§¬ LangGraphæ•™ç¨‹(äºŒ)ï¼šæŒæ¡Agentæ ¸å¿ƒèƒ½åŠ›-å·¥å…·è°ƒç”¨ï¼ˆè‡ªå®šä¹‰ã€é¢„æ„å»ºä¸MCPï¼‰
description: æœ¬æ–‡æ˜¯ ã€ŠLangGraphå…¥é—¨å…¨è§£ã€‹ç³»åˆ—çš„ç¬¬äºŒç¯‡ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä¸ºèŠå¤©æœºå™¨äººå¢åŠ æœç´¢å·¥å…·ï¼Œåˆ†åˆ«å±•ç¤ºä½¿ç”¨langchainçš„è‡ªå®šä¹‰å·¥å…·å’Œæ„å»ºMCP Serveræ–¹å¼ã€‚LangGraphè°ƒç”¨å·¥å…·, LangGraph ToolNode, LangGraphè‡ªå®šä¹‰å·¥å…·, LangGraph MCP
date: 2025-09-04
updateDate: 2025-09-04
tags: ["LangGraph","AI","LLM","MCP"]
cover: cover/264605ee-e889-80b3-a6c6-e66d154e6f95_c743460aebf1b29f2acc55931bc0f003.png
---

æœ¬æ–‡æ˜¯ **ã€ŠLangGraphå…¥é—¨å…¨è§£ã€‹**[**LangGraphå…¥é—¨æŒ‡å—ï¼šä»åŸºç¡€ChatBotåˆ°å¤šæ™ºèƒ½ä½“å®æˆ˜**](https://www.wileyzhang.com/posts/264605ee-e889-806e-b847-ce4e7bcba614) ç³»åˆ—çš„ç¬¬äºŒç¯‡ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä¸ºèŠå¤©æœºå™¨äººå¢åŠ æœç´¢å·¥å…·ï¼Œåˆ†åˆ«å±•ç¤ºä½¿ç”¨langchainçš„è‡ªå®šä¹‰å·¥å…·å’Œæ„å»ºMCP Serveræ–¹å¼ã€‚å¦‚æœå‡ºä½ æ˜¯æ–°æ‰‹ï¼Œå»ºè®®å…ˆé˜…è¯»ä¸»æŒ‡å—ä»¥äº†è§£LangGraphçš„å…¨è²Œã€‚


# åœ¨LangGraphä¸­è°ƒç”¨å·¥å…·


LLM åœ¨å¤„ç†**å®æ—¶æ€§é—®é¢˜**ã€**æ•°å­¦è®¡ç®—**ç­‰æ–¹é¢å¾€å¾€è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†å¼¥è¡¥è¿™äº›ä¸è¶³ï¼Œä¸€ä¸ªåˆæ ¼çš„ Agent åº”å½“å…·å¤‡**è°ƒç”¨å¤–éƒ¨å·¥å…·çš„èƒ½åŠ›**ã€‚


æœ¬æ–‡å°†ä»æœ€å¸¸è§çš„ **Web æœç´¢å·¥å…·** å…¥æ‰‹ï¼Œå¸¦ä½ å¿«é€Ÿä¸Šæ‰‹ LangGraph çš„å·¥å…·è°ƒç”¨ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ [TavilySearch](https://app.tavily.com/)(https://app.tavily.com) ä½œä¸ºç¤ºä¾‹ï¼ˆæ–°ç”¨æˆ·æœ‰ 1000 æ¬¡å…è´¹æœç´¢é¢åº¦ï¼‰ã€‚


åœ¨ä¸€æ„å»ºèŠå¤©æœºå™¨äººçš„åŸºç¡€ä¸Šï¼Œåªéœ€**å°‘é‡æ–°å¢ä»£ç **ï¼Œå³å¯å®Œæˆå·¥å…·è°ƒç”¨ã€‚LangGraph å·²ç»å¸®æˆ‘ä»¬å°è£…äº†å¤§éƒ¨åˆ†å¤æ‚é€»è¾‘ã€‚


### ç¤ºä¾‹ä»£ç 


```python
from typing import Annotated
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from pydantic import SecretStr
from langchain_tavily import TavilySearch
from langgraph.prebuilt import ToolNode, tools_condition

# æ­¤å¤„å®šä¹‰ä½ è‡ªå·±çš„æ¨¡å‹
llm = ChatOpenAI(base_url="http://127.0.0.1:8000/v1", api_key=SecretStr("123123"), model="qwen3_32")

# å®šä¹‰å·¥å…·
tool = TavilySearch(tavily_api_key="ä½ çš„tavily apikey", max_results=2)
tools = [tool]
# å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
llm_with_tools = llm.bind_tools(tools)

# å®šä¹‰å›¾çŠ¶æ€
class State(TypedDict):
    messages: Annotated[list, add_messages]  # æ­¤å¤„ç»´æŠ¤å®Œæ•´çš„æ¶ˆæ¯å†å²

graph = StateGraph(State)

def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}
# ä½¿ç”¨LangGraphæä¾›çš„å·¥å…·èŠ‚ç‚¹
tool_node = ToolNode(tools=tools)

graph.add_node("chatbot", chatbot)
# æ·»åŠ å·¥å…·èŠ‚ç‚¹
graph.add_node("tools", tool_node)
# æ·»åŠ å·¥å…· æ¡ä»¶åˆ†æ”¯
graph.add_conditional_edges(
    "chatbot",
    tools_condition,
)
graph.add_edge("tools", "chatbot")
graph.add_edge(START, "chatbot")

app = graph.compile()

if __name__ == "__main__":
    messages = []
    while True:
        user_input = input("ğŸ‘¨ğŸ’»: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Exiting...")
            break
        messages.append({"role": "user", "content": user_input})
        response = app.invoke({"messages": messages})
        messages = response["messages"]
        print(f'ğŸ¤–: {response["messages"][-1].content}')
```


### æ•ˆæœå¦‚ä¸‹


![7ccf1108-a281-4503-b780-ed73fbdbf17c.png](images/264605ee-e889-80b3-a6c6-e66d154e6f95/264605ee-e889-80b3-a6c6-e66d154e6f95_5ce289cb86ce538dd3fd7b2b51961f16.png)


## LangGraphè‡ªå®šä¹‰å·¥å…·ä¸å·¥å…·èŠ‚ç‚¹


LangChainä¸ºæˆ‘ä»¬é¢„æ„å»ºäº†å¾ˆå¤šå·¥å…·ï¼Œå¸¸ç”¨çš„æœ‰

- **æœç´¢ç±»**: Bing, SerpAPI, Tavily
- **ä»£ç æ‰§è¡Œç±»**: Python REPL, Node.js REPL
- **æ•°æ®åº“ç±»**: SQL, MongoDB, Redis
- **Web æ•°æ®ç±»**: Scraping and browsing
- **å…¶ä»– API**: OpenWeatherMap, NewsAPI ç­‰

ä¸è¿‡ï¼Œåœ¨**çœŸå®çš„ä¼ä¸šå¼€å‘åœºæ™¯**ä¸­ï¼Œæ›´å¸¸è§çš„åšæ³•æ˜¯å¼€å‘ **è‡ªå®šä¹‰å·¥å…·**ï¼Œä»¥æ»¡è¶³ä¸ªæ€§åŒ–éœ€æ±‚ã€‚


ä¸‹é¢æ¼”ç¤ºä¸€ä¸ªåŸºäº `BaseTool` çš„è‡ªå®šä¹‰ Tavily æœç´¢å·¥å…·ï¼Œä»¥åŠå¦‚ä½•åœ¨ LangGraph ä¸­æ¥å…¥ã€‚


### ç¤ºä¾‹ä»£ç 


```python
import json
from langchain_core.messages import ToolMessage
from langgraph.constants import END
from typing import Annotated, Type, Optional
from langchain_core.callbacks import CallbackManagerForToolRun, AsyncCallbackManagerForToolRun

from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from pydantic import SecretStr, BaseModel, Field
from langchain_core.tools import BaseTool
from tavily import TavilyClient, AsyncTavilyClient

# è‡ªå®šä¹‰å·¥å…·éƒ¨åˆ†
class TavilySearchInput(BaseModel):
    query: str = Field(description=("æœç´¢æŸ¥è¯¢"))

class TavilySearchTool(BaseTool):
    name: str = "tavily_search"
    description: str = """ä¸€ä¸ªé’ˆå¯¹å…¨é¢ã€å‡†ç¡®å’Œå¯ä¿¡çš„ç»“æœè¿›è¡Œäº†ä¼˜åŒ–çš„æœç´¢å¼•æ“ã€‚
å½“éœ€è¦å›ç­”æœ‰å…³æ—¶äº‹çš„é—®é¢˜æ—¶å¾ˆæœ‰ç”¨ã€‚
è¾“å…¥åº”è¯¥æ˜¯æœç´¢æŸ¥è¯¢ã€‚"""
    args_schema: Type[BaseModel] = TavilySearchInput
    # return_direct: bool = True

    def _run(
        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> int:
        client = TavilyClient()
        search_r = client.search(query=query, max_results=2)
        return search_r

    async def _arun(
        self,
        query: str,
        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
    ) -> int:
        client = AsyncTavilyClient()
        search_r = await client.search(query=query, max_results=2)
        return search_r

# è‡ªå®šä¹‰çš„å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
class ToolNode:
    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}

    def __call__(self, inputs: dict):
        if messages := inputs.get("messages", []):
            message = messages[-1]
        else:
            raise ValueError("No message found in input")
        outputs = []
        for tool_call in message.tool_calls:
            print(f'æ­£åœ¨æ‰§è¡Œå·¥å…· {tool_call["name"]}ï¼Œå‚æ•° {tool_call["args"]}')
            tool_result = self.tools_by_name[tool_call["name"]].invoke(
                tool_call["args"]
            )
            print(f'å·¥å…·{tool_call["name"]}, æ‰§è¡Œç»“æœ{json.dumps(tool_result, ensure_ascii=False)}')
            outputs.append(
                ToolMessage(
                    content=json.dumps(tool_result, ensure_ascii=False),
                    name=tool_call["name"],
                    tool_call_id=tool_call["id"],
                )
            )
        return {"messages": outputs}

# æ­¤å¤„å®šä¹‰ä½ è‡ªå·±çš„æ¨¡å‹
llm = ChatOpenAI(base_url="http://127.0.0.1:8000/v1", api_key=SecretStr("123123"), model="qwen3_32")
# å®šä¹‰å·¥å…·
tool = TavilySearchTool()
tools = [tool]
# å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
llm_with_tools = llm.bind_tools(tools)
# å®šä¹‰å›¾çŠ¶æ€
class State(TypedDict):
    messages: Annotated[list, add_messages]  # æ­¤å¤„ç»´æŠ¤å®Œæ•´çš„æ¶ˆæ¯å†å²
graph = StateGraph(State)
def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

# å·¥å…·è·¯ç”±
def route_tools(state: State):
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"No messages found in input state to tool_edge: {state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return END

# ä½¿ç”¨LangGraphæä¾›çš„å·¥å…·èŠ‚ç‚¹
tool_node = ToolNode(tools=tools)
graph.add_node("chatbot", chatbot)
# æ·»åŠ å·¥å…·èŠ‚ç‚¹
graph.add_node("tools", tool_node)
# æ·»åŠ å·¥å…·æ¡ä»¶è¾¹
graph.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", END: END},
)
graph.add_edge("tools", "chatbot")
graph.add_edge(START, "chatbot")
app = graph.compile()

if __name__ == "__main__":
    messages = []
    while True:
        user_input = input("ğŸ‘¨ğŸ’»: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Exiting...")
            break
        messages.append({"role": "user", "content": user_input})
        response = app.invoke({"messages": messages})
        messages = response["messages"]
        print(f'ğŸ¤–: {response["messages"][-1].content}')
```


### **æ•ˆæœå¦‚ä¸‹**


æˆ‘ä»¬åœ¨å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ï¼Œæ‰“å°å·¥å…·çš„æ‰§è¡Œä¿¡æ¯


![0829cf43-9a82-4f65-bcfc-d9986539fbc2.png](images/264605ee-e889-80b3-a6c6-e66d154e6f95/264605ee-e889-80b3-a6c6-e66d154e6f95_f55ae8872878bafdd8afafc0f3d1bcf4.png)


é™¤äº†ç»§æ‰¿ `BaseTool` çš„æ–¹å¼ï¼ŒLangChain è¿˜æ”¯æŒé€šè¿‡ **`@tool`** **è£…é¥°å™¨** æ¥å¿«é€Ÿå®šä¹‰å·¥å…·ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè¿™ç§æ–¹æ³•æ›´ç®€æ´ï¼Œé€‚åˆè½»é‡çº§å·¥å…·


```python
from typing import Annotated
from tavily import TavilyClient
from langchain_core.tools import tool


@tool("tavily_search")
def tavily_search_tool(query: Annotated[str, "æœç´¢æŸ¥è¯¢"]):
"""ä¸€ä¸ªé’ˆå¯¹å…¨é¢ã€å‡†ç¡®å’Œå¯ä¿¡çš„ç»“æœè¿›è¡Œäº†ä¼˜åŒ–çš„æœç´¢å¼•æ“ã€‚å½“éœ€è¦å›ç­”æœ‰å…³æ—¶äº‹çš„é—®é¢˜æ—¶å¾ˆæœ‰ç”¨ã€‚è¾“å…¥åº”è¯¥æ˜¯æœç´¢æŸ¥è¯¢ã€‚"""client = TavilyClient()
    search_r = client.search(query=query)
    return search_r

tavily_search_tool.invoke({"query": "åŒ—äº¬2025å¹´8æœˆ27æ—¥å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"})
```


## LangGraphè°ƒç”¨MCP


é™¤äº†è‡ªå®šä¹‰å·¥å…·ä¹‹å¤–ï¼ŒLangGraph è¿˜æ”¯æŒ **MCPï¼ˆModel Context Protocolï¼‰**ï¼Œè¿™ä½¿å¾—å·¥å…·çš„å¤ç”¨å’Œæ‰©å±•æ€§æ›´å¼ºã€‚


è¦åœ¨ LangGraph ä¸­ä½¿ç”¨ MCPï¼Œéœ€è¦é¢å¤–å®‰è£…ä¾èµ–åŒ…ï¼š


```plain text
pip install langchain-mcp-adapters
```


### ç¼–å†™ä¸€ä¸ªç®€å•çš„MCP Server


å…³äºMCP Serverç¼–å†™ï¼Œå‚è€ƒä¹‹å‰çš„æ–‡ç« [https://www.wileyzhang.com/posts/222605ee-e889-8098-b91e-f684acac99d2](https://www.wileyzhang.com/posts/222605ee-e889-8098-b91e-f684acac99d2)


ä¾æ—§æ˜¯ä»¥Tavilyæœç´¢ä¸ºä¾‹


```python
import json
from mcp.server.fastmcp import FastMCP
from tavily import TavilyClient
mcp = FastMCP("search")

@mcp.tool()
async def tavily_search(query: str) -> str:
"""ä¸€ä¸ªé’ˆå¯¹å…¨é¢ã€å‡†ç¡®å’Œå¯ä¿¡çš„ç»“æœè¿›è¡Œäº†ä¼˜åŒ–çš„æœç´¢å¼•æ“ã€‚å½“éœ€è¦å›ç­”æœ‰å…³æ—¶äº‹çš„é—®é¢˜æ—¶å¾ˆæœ‰ç”¨ã€‚è¾“å…¥åº”è¯¥æ˜¯æœç´¢æŸ¥è¯¢ã€‚"""client = TavilyClient()
    search_r = client.search(query=query, max_results=2)
    return json.dumps(search_r, ensure_ascii=False)

if __name__ == "__main__":
    mcp.run(transport="streamable-http")
```


### **LangGrpah+MCPå®Œæ•´ç¤ºä¾‹ä»£ç **


```python
import asyncio
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import ToolNode, tools_condition
from typing import Annotated
from typing_extensions import TypedDict
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from pydantic import SecretStr

# æ­¤å¤„å®šä¹‰ä½ è‡ªå·±çš„æ¨¡å‹
llm = ChatOpenAI(base_url="http://127.0.0.1:8000/v1", api_key=SecretStr("123123"), model="qwen3_32")
# é…ç½®MCP Server
client = MultiServerMCPClient(
    {
        "search": {
            "url": "http://localhost:8000/mcp/",
            "transport": "streamable_http",
        }
    }
)

class State(TypedDict):
    messages: Annotated[list, add_messages]  # æ­¤å¤„ç»´æŠ¤å®Œæ•´çš„æ¶ˆæ¯å†å²
graph = StateGraph(State)

async def main():
    tools = await client.get_tools()
    # å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
    llm_with_tools = llm.bind_tools(tools)
    def chatbot(state: State):
        return {"messages": [llm_with_tools.invoke(state["messages"])]}
    graph = StateGraph(State)
    graph.add_node(chatbot)
    graph.add_node(ToolNode(tools))
    graph.add_edge(START, "chatbot")
    graph.add_conditional_edges(
        "chatbot",
        tools_condition,
    )
    graph.add_edge("tools", "chatbot")
    app = graph.compile()
    messages = []
    while True:
        user_input = input("ğŸ‘¨ğŸ’»: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Exiting...")
            break
        messages.append({"role": "user", "content": user_input})
        response = await app.ainvoke({"messages": messages})
        messages = response["messages"]
        print(f'ğŸ¤–: {response["messages"][-1].content}')

asyncio.run(main())
```


### æ•ˆæœå¦‚ä¸‹


![36eb07df-cfd9-4ada-8218-995c44fff6ba.png](images/264605ee-e889-80b3-a6c6-e66d154e6f95/264605ee-e889-80b3-a6c6-e66d154e6f95_a6337004c4014de551009b267a4508bd.png)


å¸¦å·¥å…·è°ƒç”¨çš„bot graphå›¾å¦‚ä¸‹


![300bd9ae-cbc4-4ecd-b272-59a60841c844.png](images/264605ee-e889-80b3-a6c6-e66d154e6f95/264605ee-e889-80b3-a6c6-e66d154e6f95_e81e77e86aa7e9b52cf55f4150c1a2bc.png)

